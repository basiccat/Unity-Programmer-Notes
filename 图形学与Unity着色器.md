- [3D数学](#3d数学)
  - [为什么需要这么多坐标空间？](#为什么需要这么多坐标空间)
  - [坐标空间的变换](#坐标空间的变换)
  - [点积](#点积)
  - [叉积](#叉积)
  - [浮点数误差](#浮点数误差)
  - [正交矩阵](#正交矩阵)
  - [变换矩阵的意义](#变换矩阵的意义)
  - [变换矩阵里每一列代表什么](#变换矩阵里每一列代表什么)
  - [线性变换](#线性变换)
  - [旋转有哪几种方式？](#旋转有哪几种方式)
  - [欧拉角会有什么问题？](#欧拉角会有什么问题)
  - [简述四元数的作用，四元数对欧拉角的优点？](#简述四元数的作用四元数对欧拉角的优点)
  - [为什么使用4*4齐次矩阵](#为什么使用44齐次矩阵)
  - [投影矩阵](#投影矩阵)
  - [屏幕空间](#屏幕空间)
  - [变换法线](#变换法线)
- [渲染管线](#渲染管线)
  - [渲染流水线的3个阶段：应用阶段，几何阶段，光栅化阶段](#渲染流水线的3个阶段应用阶段几何阶段光栅化阶段)
  - [CPU如何向Shader传递数据？数据可否在Shader中修改？](#cpu如何向shader传递数据数据可否在shader中修改)
  - [顶点着色器作用，包括什么工作](#顶点着色器作用包括什么工作)
  - [顶点着色器到片元着色器中间流程](#顶点着色器到片元着色器中间流程)
  - [提前深度测试](#提前深度测试)
  - [Unity3D Shader分哪几种，有什么区别？](#unity3d-shader分哪几种有什么区别)
  - [为什么要用FrameBuffer](#为什么要用framebuffer)
  - [背面剔除是什么， 正面剔除是什么？](#背面剔除是什么-正面剔除是什么)
  - [如何在Shader中获取摄像机的位置？](#如何在shader中获取摄像机的位置)
  - [RenderType 标签](#rendertype-标签)
- [光照](#光照)
  - [BRDF](#brdf)
  - [Phong和Billin-Phong](#phong和billin-phong)
  - [逐像素光照和逐顶点光照](#逐像素光照和逐顶点光照)
  - [半兰伯特(Half Lambert)光照模型](#半兰伯特half-lambert光照模型)
  - [球谐光照的理解](#球谐光照的理解)
  - [光源的5个属性](#光源的5个属性)
  - [Unity提供了几种光源](#unity提供了几种光源)
  - [实时点光源的优缺点是什么？](#实时点光源的优缺点是什么)
  - [什么是LightMap？](#什么是lightmap)
  - [光照探针](#光照探针)
- [渲染路径](#渲染路径)
  - [前向渲染路径](#前向渲染路径)
  - [延迟渲染路径](#延迟渲染路径)
    - [G-Buffer的底层结构](#g-buffer的底层结构)
    - [光体积(Light Volumes)](#光体积light-volumes)
    - [为什么延迟渲染对MSAA支持不好](#为什么延迟渲染对msaa支持不好)
- [阴影](#阴影)
  - [shadowmap实现原理](#shadowmap实现原理)
  - [接收阴影和投射阴影是两个过程](#接收阴影和投射阴影是两个过程)
  - [屏幕空间的阴影算法原理](#屏幕空间的阴影算法原理)
  - [SHADOW_COORDS TRANSFER_SHADOW SHADOW_ATTENUATION](#shadow_coords-transfer_shadow-shadow_attenuation)
- [纹理](#纹理)
  - [纹理映射坐标](#纹理映射坐标)
  - [纹理滤波](#纹理滤波)
  - [MipMap是什么，作用？](#mipmap是什么作用)
  - [凹凸映射](#凹凸映射)
  - [立方体纹理](#立方体纹理)
  - [菲涅尔反射](#菲涅尔反射)
  - [渲染目标纹理](#渲染目标纹理)
  - [命令缓冲(Command Buffer)](#命令缓冲command-buffer)
  - [深度纹理](#深度纹理)
  - [噪声纹理](#噪声纹理)
- [透明效果](#透明效果)
  - [如何渲染半透明物体](#如何渲染半透明物体)
  - [透明物体和不透明物体渲染顺序](#透明物体和不透明物体渲染顺序)
  - [透明渲染队列，和普通渲染队列有什么不同，系统如何处理的？](#透明渲染队列和普通渲染队列有什么不同系统如何处理的)
  - [请问alpha test在何时使用？能达到什么效果？](#请问alpha-test在何时使用能达到什么效果)
  - [alpha blend工作原理](#alpha-blend工作原理)
  - [ShaderLab的混合命令](#shaderlab的混合命令)
- [屏幕后处理](#屏幕后处理)
  - [Bloom](#bloom)
  - [动态模糊](#动态模糊)
  - [边缘检测](#边缘检测)
- [非真实感渲染(Non-Photorealistic Rendering)](#非真实感渲染non-photorealistic-rendering)
  - [卡通渲染思路](#卡通渲染思路)
  - [描边](#描边)
  - [Outlines](#outlines)
- [渲染优化技术](#渲染优化技术)
  - [Graphics performance fundamentals](#graphics-performance-fundamentals)
  - [优化shader](#优化shader)
    - [shader中的if会造成性能影响以及优化](#shader中的if会造成性能影响以及优化)
  - [Drawcall](#drawcall)
    - [SetPass Call 是什么？](#setpass-call-是什么)
    - [如何降低DrowCall？](#如何降低drowcall)
  - [批处理](#批处理)
    - [Dynamic Batching](#dynamic-batching)
    - [Static Batching](#static-batching)
    - [GPU Instancing](#gpu-instancing)
  - [其它](#其它)
    - [LOD是什么，优缺点是什么？](#lod是什么优缺点是什么)
    - [Cast Shadows](#cast-shadows)
  - [Light Culling Mask](#light-culling-mask)
    - [MeshRender中material和sharedmaterial的区别？](#meshrender中material和sharedmaterial的区别)
    - [Cloned Materials](#cloned-materials)
- [基于物理的渲染](#基于物理的渲染)
  - [PBS](#pbs)
  - [PBS适合什么样的游戏](#pbs适合什么样的游戏)
  - [伽马校正 gamma correction](#伽马校正-gamma-correction)
  - [HDR与LDR的区别](#hdr与ldr的区别)
- [解析几何](#解析几何)
  - [相交测试](#相交测试)
  - [点到平面的距离如何计算](#点到平面的距离如何计算)
  - [光线和平面的交点](#光线和平面的交点)
  - [如何判断是凸多边形还是凹多边形](#如何判断是凸多边形还是凹多边形)
  - [AABB包围盒 OBB包围盒](#aabb包围盒-obb包围盒)
- [资料](#资料)
  - [《Unity Shader入门精要》](#unity-shader入门精要)
  - [Shader Tutorials by Ronja](#shader-tutorials-by-ronja)

# 3D数学

## 为什么需要这么多坐标空间？

开发人员需要不同的坐标空间，因为某些信息是有意义的或仅在特定上下文环境中可用。

模型/对象空间是与特定对象关联的坐标空间，每个对象都有自己独立的对象空间。

世界坐标系是一个特殊的坐标系，它为所有其它要指定的坐标系建立了一个“全局”参考系。换句话说，**我们可以用世界坐标空间来表达其它坐标空间的位置**，但我们不能用更大的外部坐标空间来表示世界坐标空间。

观察/相机空间是与渲染的视点相关联的对象空间。

对于模型空间和世界空间，Unity使用的是左手坐标系，这可以从Scene视图的坐标轴显示看出来。

**但对于观察空间，Unity使用的是右手坐标系，摄像机的前向是Z轴的负方向，这与在模型空间和世界空间中的定义相反。也就是说，Z轴坐标减少意味着场景深度的增加。**

裁剪/齐次裁剪空间的目标是能够方便地对渲染图元进行裁剪。这里用于变换的矩阵叫**裁剪矩阵**或**投影矩阵**。

屏幕空间是一个二维空间，我们将把顶点从裁剪空间投影到屏幕空间中，来生成对应的2D坐标。

## 坐标空间的变换
要想定义一个坐标空间，必须指明其原点位置和3个坐标轴的方向，而这些值实际上是相对于另一个坐标空间的。

对坐标空间的变换实际上就是在父空间和子空间之间对点和矢量进行变换。

## 点积
两个单位矢量的点积等于它们之间夹角的余弦值。

不限长度的向量b在**单位**向量a方向上的**有符号**投影，点积的符号可以让我们知道两个矢量的方向关系。

## 叉积
[叉积 - 维基百科](https://zh.wikipedia.org/wiki/%E5%8F%89%E7%A7%AF)

叉积不满足交换律。

aXb的长度等于a和b的模的乘积再乘以它们之间夹角的**正弦值**。

左手坐标系用左手法则判断叉积的方向。

最常见的应用是计算垂直于一个平面、三角形的矢量，另外还可以判断三角面片的朝向。

## 浮点数误差
Epsilin是针对浮点数的误差问题所指定的容差（tolerance）。

注意矩阵的蠕变：误差的积累

对抗蠕变：正交化

## 正交矩阵
如果一个方阵M和它的转置矩阵的乘积是单位矩阵的话，我们就说这个矩阵是正交的，反过来说也是成立的。

如果一个矩阵是正交的，那么它的转置矩阵和逆矩阵是一样的。

逆矩阵计算很复杂，但是转置矩阵非常容易计算。

旋转矩阵是正交矩阵。

## 变换矩阵的意义
关于变换矩阵，应该知道：矩阵并没有什么神奇的地方，一旦我们明白了，
>坐标最好被理解为基矢量的线性组合中的**系数**，我们就知道进行变换时需要知道的所有数学。

矩阵只是一种简单的将某些事写下来的方式。为什么要通过矩阵表示法来表示坐标空间的变换？有一个不明显但令人信服的理由：使用线性代数中的大型通用工具集。

## 变换矩阵里每一列代表什么
```
          |   |   |     -- xB --
MA->B =   xA  yA  zA  = -- yB -- 
          |   |   |     -- zB --
```

如果我们知道坐标空间的变换矩阵A->B是一个正交矩阵，那么我们可以提取它的第一列来得到坐标空间A的x轴在坐标空间B下的表示，还可以提取它的第一行来得到坐标空间B的x轴在坐标空间A下的表示。

反过来说，如果我们知道坐标空间B的x轴、y轴和c轴（必须是单位矢量，否则构建出来的就不是正交矩阵了）在坐标空间A下的表示，把它们依次放在矩阵的每一行就可以得到从A到B的变换矩阵了。

## 线性变换
线性变换指的是那些可以保留矢量加和标量乘的变换。

>F(a+b) = F(a) + F(b) 且 F(ka) = kF(a)

常见用于表示线性变换：旋转、缩放

仿射变换：线性变换 + 平移

## 旋转有哪几种方式？

比较|矩阵|欧拉角|四元数
---|---|---|---
在坐标空间之间旋转点|可能|不可能|要转换为旋转矩阵
多次旋转的连接|可能|不可能|可能
旋转反转|使用转置矩阵|不容易|使用四元数共轭
插值|非常有问题|有万向节死锁问题|Slerp可提供平滑插值
直接人工解释|难|最简单|难
存储效率|9个数字|3个数字|4个数字
给定旋转唯一表示|唯一|否|两种表示互为负数
可能无效|矩阵蠕变|不会|错误蠕变

表示方式之间的转化：

    欧拉角 矩阵
    矩阵 欧拉角

    四元数 矩阵
    矩阵 四元数

    欧拉角 四元数
    四元数 欧拉角

## 欧拉角会有什么问题？
一旦选择了90°作为俯仰角的范围，我们就被限制为围绕垂直轴旋转，这种现象被称为万向节死锁（Gimbal Lock），即第二次旋转的90°角限制了可以使第一次和第三次旋转绕同一个轴旋转。为了从欧拉角三元组的规范集中消除这种别名现象，我们将围绕垂直轴的所有旋转分配给万向节死锁情形下的航向。换句话说，在规范集中，如果俯仰角为90°，则滚转角为0°。

## 简述四元数的作用，四元数对欧拉角的优点？

四元数包含标量分量w，三维矢量分量xyz。四元数包含轴和角度，但是轴和角度的编码方式看起来很奇怪。

四元数可以通过使用**旋转轴**和**绕该轴旋转的量**来表示角位移。

四元数乘法可用于将多个旋转连接成单个角位移。

四元数用于平滑插值，Slerp插值方法提供了定向之间的平滑插值。

相对欧拉角的优点：
- 增量旋转
- 避免万向锁
- 给定方位的表达式有2种，互为正负（欧拉角有无数种表达方式）

## 为什么使用4*4齐次矩阵
四维矢量的第四个分量是w，称为齐次坐标。
物理三维点可以被认为是存在于四维的w=1的超平面（Hyperplane）中。

通过除以w的方式产生的齐次坐标和投影是有意义的，有两个原因促使我们使用四维矢量和4X4齐次矩阵：
- 以某种方式扩展标准3X3变换矩阵以便能够处理包括**平移**的变换
- 如果将适当的值放入w中，则齐次除法将导致透视投影

四维矢量的w分量可用于选择性地“开关”4X4矩阵的平移部分。因为一些矢量代表“位置”，所以它应该被平移；而其它矢量代表“方向”，所以它不应该被平移。在几何意义上，可以将第一类数据（w=1）视为“点”，将第二类数据(w=0)视为“矢量”。

## 投影矩阵
把顶点从观察空间转换到裁剪空间中。

投影矩阵有两个目的：
- 为投影做准备，虽然名字包含了投影二字，但是它并没有进行真正的投影工作，而是在为投影做准备。真正的投影发生在后面的齐次除法过程中，而经过投影矩阵的变换后，顶点的w分量具有了特殊的意义。
- 是对x、y和z分量进行缩放，经过投影矩阵的缩放后，可以直接使用w分量作为一个范围值，如果x、y和z分量都在这个范围内，说明该顶点位于裁剪空间内。

**投影矩阵也会改变空间的旋向性：空间从右手坐标系变换到了左手坐标系。这意味着，离摄像机越远，z值将越大。**

透视投影矩阵的乘法并不真正执行透视变换，它只是计算恰当的分母给w。当通过除以w将四维转换为三维时，就会执行真正的透视除法。

## 屏幕空间
把顶点从裁剪空间投影到屏幕空间，有两个步骤：
- 进行标准**齐次除法**，也被称为透视除法，就是用齐次坐标系的w分量去除x,y,z分量。我们把这一步得到的坐标叫做归一化设备坐标（NDC）。经过齐次除法后，透视投影和正交投影的视锥体都变换到一个相同的立方体内。
- 进行屏幕映射，这个映射的过程就是一个缩放的过程。屏幕空间的左下角的像素坐标是（0，0），右上角的像素坐标是（pixelWidth,pixelHeight）。z分量通常被用于深度缓冲。

在Unity中，从裁剪空间到屏幕空间的转换是由底层帮我们完成的，我们的顶点着色器只需要把顶点转换到裁剪空间即可。

## 变换法线
当变换一个模型的时候不仅需要变换它的顶点，还需要变换顶点法线，以便在后续处理中计算光照。

如果变换中包含了非统一变换，那么就必须求解**原变换矩阵的逆转置矩阵**来变换法线。

# 渲染管线

## 渲染流水线的3个阶段：应用阶段，几何阶段，光栅化阶段

应用阶段：开发者决定哪些向几何阶段输出渲染所需的信息。
- 把数据加载到显存中
- CPU设置渲染状态，定义场景中的网格是怎样被渲染的
- 调用draw call

几何阶段：处理所有和我们要绘制的几何相关的事物。

- 顶点着色器：可编程，顶点空间变换，顶点着色等
- 曲面细分着色器：可选，细分图元，增加物体表面三角形数量，再将这些新三角形偏移到适当位置。
- 几何着色器：可选，执行逐图元着色操作，或者产生更多的图元；可以创建或销毁几何体。
- 裁剪：可配置，将那些不在摄像机视野内的顶点裁剪掉，并剔除某些三角图元的面片
- 屏幕映射：把每个图元的坐标转换到屏幕坐标系中，屏幕坐标系是一个二维坐标系，和显示分辨率有很大关系

光栅化阶段：计算每个图元覆盖了哪些像素，以及为这些像素计算它们的颜色。

- 三角形设置：点到边，得到三角形边界的表示方式。
- 三角形遍历：判断一个三角形网格覆盖了哪些像素，并使用三角网格3个顶点的顶点信息**对整个覆盖区域的像素进行插值**，最终得到一个片元序列。
- 像素/片元着色器：完全可编程，实现逐片元的着色操作
- 逐片元操作：高度可配置，模板测试，深度测试，混合，修改颜色等

## CPU如何向Shader传递数据？数据可否在Shader中修改？
配置渲染流水线。

顶点与定点输入布局：
- VAO（vertex-array object）顶点数组对象，用来管理VBO。
- VBO（vertex buffer object）顶点缓冲对象，用来缓存用户传入的顶点数据。
- EBO（element / index buffer object）索引缓冲对象，用来存放顶点索引数据。

CPU和GPU交互：
命令队列和命令列表
CPU和GPU间的同步

## 顶点着色器作用，包括什么工作
顶点着色器需要完成的工作主要有：坐标变换，逐顶点光照，输出后续阶段所需的其它数据

一个最基本的顶点着色器必须完成的一个工作是，把顶点坐标从模型空间转换到齐次裁剪空间。经过硬件做透视除法后，最终会得到归一化设备坐标（NDC）。

## 顶点着色器到片元着色器中间流程
曲面细分着色器，几何着色器，裁剪，屏幕映射，三角形设置，三角形遍历

如何通信？
```
struct v2f
{
  float4 pos : SV_POSITION;
  fixed3 color : COLOR0;
};
```

片元着色器中的输入实际上是把顶点着色器的输出进行插值后的结果。

## 提前深度测试
现代GPU会尽可能在执行片元着色器前就进行深度测试。GPU会判断片元着色器中的操作是否会和提前测试发生冲突，如果有冲突，就会禁用深度测试，但这样会导致性能下降，因为需要处理更多的片元，这也是透明度测试会降低性能的原因。

现在大部分的GPU都提供一个叫做提前深度测试(Early Depth Testing)的硬件特性。提前深度测试允许深度测试在片段着色器之前运行。只要我们清楚一个片段永远不会是可见的（它在其他物体之后），我们就能提前丢弃这个片段。

片段着色器通常开销都是很大的，所以我们应该尽可能避免运行它们。当使用提前深度测试时，片段着色器的一个限制是你不能写入片段的深度值。如果一个片段着色器对它的深度值进行了写入，提前深度测试是不可能的。OpenGL不能提前知道深度值。

## Unity3D Shader分哪几种，有什么区别？
表面着色器的是Unity对顶点/片元着色器的更高一层的抽象，它可以轻松地以简洁方式处理很多光照细节。表面着色器可同时在前向渲染及延迟渲染模式下正常工作。

顶点/片元着色器可以非常灵活地实现需要的效果，但是需要编写更多的代码。

固定功能管线着色器可以作为前两种着色器的备用选择，当硬件无法运行那些酷炫Shader的时，还可以通过固定功能管线着色器来绘制出一些基本的内容。

## 为什么要用FrameBuffer
避免我们看到那些正在光栅化的图元，GPU使用双重缓冲（Double Buffering）的策略。这意味着，对场景的渲染是在幕后发生的，即在后置缓冲（Back Buffer）中。一旦场景已经被渲染到了后置缓冲中，GPU就会交换后置缓冲区和前置缓冲区中的内容。

## 背面剔除是什么， 正面剔除是什么？
Cull Back | Front | Off

## 如何在Shader中获取摄像机的位置？
_WorldSpaceCameraPos

## RenderType 标签
使用 RenderType 标签可覆盖 Shader 对象的行为。

在内置渲染管线中，可以使用一种称为着色器替换的技术在运行时交换子着色器。此技术的工作方式是标识具有匹配 RenderType 标签值的子着色器。

在运行时替换着色器

在内置渲染管线中，可以让摄像机在运行时更改用于渲染特定几何体的着色器。可以这样做以实现视觉效果，例如边缘检测。

# 光照

## BRDF
当给定入射光线的方向和辐照度后，双向反射分布函数可以给出在某个出射方向上的光照能量分布。

大部分BRDF是对真实场景进行理想化和简化后的模型，它们并不能真实地反映出物体和光线之间的交互，这些光照模型都是**经验模型**。

## Phong和Billin-Phong

著名学者裴祥凤（Bui Tuong Phong）提出了**标准光照模型**背后的基本原理。标准光照模型只关心直接光照，也就是那些直接从光源发射出来照射到物体表面后，经过物体表面的一次反射直接进入摄像机的光线。它把进入到摄像机的光线分为了4个部分，每个部分使用一种方法来计算它的贡献度。
- 自发光(emissive)给定一个方向时，一个表面本身会向该方向发射多少辐射量。只是它本身看起来更亮，不会影响周围物体。
- 环境光(ambient)描述所有其它间接光照
- 漫反射(diffuse)描述当光源照射到模型表面时，该表面会向每个方向散射多少辐射量。
- 高光反射(specular)描述当光线从光源照射到模型表面时，该表面会在完全镜面反射方向散射多少辐射量。

漫反射光照符合兰伯特定律（Lambert's Law）：反射光线的强度与表面法线和光源方向之间夹角的余弦值成正比。

计算高光反射需要知道的信息较多，Billin提出了一个简单的修改方法来得到类似的效果。避免计算反射方向。
两种光照模型都是经验模型。

漫反射计算过程：1）通过法线向量和光线入射方向求点积，得到光照强度；2）将光线颜色 * 光线强度 * 物体的表面颜色，就是我们最后看到的颜色；

镜面反射计算过程：1）光线的入射方向和法线求出反射方向；2）将反射方向和眼睛的入射方向求点积；3）以点积为底，指数是光照强度求出看到的颜色。

## 逐像素光照和逐顶点光照
逐像素光照：在面片之间对顶点法线进行插值，使用插值得到的法线计算光照。被称为Phong着色。

逐顶点光照：在每个顶点上计算光照，然后会在渲染图元内部进行线性插值，最后输出成像素颜色。也被称为高洛德着色（Gouraud Shading）。

顶点数目往往小于像素数目。

但是逐顶点光照依赖线性插值来得到像素光照，如果光照模型中有非线性计算（如计算高光反射）时，逐顶点光照会出现问题。

## 半兰伯特(Half Lambert)光照模型
我们使用的通常的漫反射光照模型也被称为兰伯特光照模型，因为它符合兰伯特定律。
在光照无法到达的区域，模型的外观通常是全黑的，失去了模型的表现细节。

对于模型的背光面，在原兰伯特光照模型中点积结果将映射到同一个值，即0；而在半兰伯特光照模型中，背光面也可以又明暗变化，不同的点积结果会映射到不同的值上。

半兰伯特没有任何物理依据，它仅仅是一个视觉加强技术。

## 球谐光照的理解
球谐光照在现代游戏图形渲染领域应用很广，用于快速的模拟复杂的实时光照，例如unity中的light probe以及一些不重要的实时光源，可以用球谐光照快速的计算。球谐光照的优点是运行时的计算量与光源的数量无关，如果参数足够却可以较好的模拟实时的光照结果。

[球谐光照入门简介](https://www.jianshu.com/p/d8d79401525f)“？？？？？？”

## 光源的5个属性
位置

方向

颜色

强度

衰减：Unity使用一张纹理作为查找表来在片元着色器中计算逐像素光照的衰减。

## Unity提供了几种光源
    平行光：Directional Light
    点光源：Point Light
    聚光灯：Spot Light
    区域光源：Area Light 仅在烘培时才可发挥作用

## 实时点光源的优缺点是什么？

可以有cookies – 带有 alpha通道的立方图(Cubemap )纹理。

点光源是最耗费资源的。

## 什么是LightMap？

LightMap:称为光照帖图,即把灯光和物体设置成静态,然后对灯光进行烘焙,此时在物体表面形成一张有灯光效果的帖图,此时把场景中的灯光删除掉,物体表面依然有灯光的效果,而这种效果是帖图造成的;光照帖图的优点是避免动态光照在场景中的实时渲染,减少drawcall;

## 光照探针

光照探针是在烘焙期间测量（探测）光照的场景位置。在运行时，系统将使用距离**动态游戏对象**最近的探针的值来估算照射到这些对象的**间接光**。

# 渲染路径

渲染路径决定了光照是如何应用到Unity Shader中的。

## 前向渲染路径
每进行一次完整的前向渲染，我们需要渲染该图元对象的渲染图元，并计算两个缓冲区的信息：一个是颜色缓冲区，一个是深度缓冲区。我们利用深度缓冲来决定一个片元是否可见，如果可见就更新颜色缓冲区中的颜色值。对于每个逐像素光源，我们都需要进行上面一次完整的渲染流程。因此渲染引擎通常会限制每个物体的逐像素光照的数目。

3种光照处理方式：逐顶点处理，逐像素处理，球谐函数处理

决定一个光源使用哪种处理模式取决于它的类型和渲染模式：
- 光源类型是指该光源是平行光还是其它类型的光源
- 渲染模式指的是该光源是否是重要的（Important）

前向渲染有两种Pass：Base Pass和Additional Pass

## 延迟渲染路径
[延迟着色法](https://learnopengl-cn.readthedocs.io/zh/latest/05%20Advanced%20Lighting/08%20Deferred%20Shading/)

当场景中包含大量实时光源时，前向渲染性能会急剧下降。延迟渲染中，除了前向渲染中使用的颜色缓冲和深度缓冲外，还会利用额外的缓冲区，称为G缓冲（Geometry buffer）。G缓冲区存储了我们所关心的表面的其他信息，例如该表面的法线，位置，用于光照计算的材质属性等。

延迟渲染主要包含两个Pass。在第一个Pass中，我们不进行任何光照计算，而是仅仅计算哪些片元是可见的，这主要是通过深度缓冲技术实现的。当发现一个片元是可见的，我们就把相关信息存储到G缓冲区。
在第二个Pass中，我们利用G缓冲的各个片元信息，进行真正的光照计算。

延迟渲染带来一些缺点：
- 大内存开销
- 迫使你对大部分场景的光照使用相同的光照算法，你可以通过包含更多关于材质的数据到G缓冲中来减轻这一缺点
- 没有MSAA
- 没有混合(仍需要正向渲染的配合)，因为G缓冲中所有的数据都是从一个单独的片段中来的，而混合需要对多个片段的组合进行操作

### G-Buffer的底层结构
下面列出了 G 缓冲区中渲染目标 (RT0 - RT4) 的默认布局。数据类型放置在每个渲染目标的各个通道中。使用的通道显示在括号内。

    RT0，ARGB32 格式：漫射颜色 (RGB)，遮挡 (A)。
    RT1，ARGB32 格式：镜面反射颜色 (RGB)，粗糙度 (A)。
    RT2，ARGB2101010 格式：世界空间法线 (RGB)，未使用 (A)。
    RT3，ARGB2101010（非 HDR）或 ARGBHalf (HDR) 格式：发射 + 光照 + 光照贴图 + 反射探针缓冲区。
    深度+模板缓冲区。

### 光体积(Light Volumes)
延迟渲染一直被称赞的原因就是它能够渲染大量的光源而不消耗大量的性能。然而，延迟渲染它本身并不能支持非常大量的光源，因为我们仍然必须要对场景中每一个光源计算每一个片段的光照分量。真正让大量光源成为可能的是我们能够对延迟渲染管线引用的一个非常棒的优化：光体积(Light Volumes)

通常情况下，当我们渲染一个复杂光照场景下的片段着色器时，我们会计算场景中每一个光源的贡献，不管它们离这个片段有多远。很大一部分的光源根本就不会到达这个片段，所以为什么我们还要浪费这么多光照运算呢？

隐藏在光体积背后的想法就是计算光源的半径，或是体积，也就是光能够到达片段的范围。由于大部分光源都使用了某种形式的衰减(Attenuation)，我们可以用它来计算光源能够到达的最大路程，或者说是半径。我们接下来只需要对那些在一个或多个光体积内的片段进行繁重的光照运算就行了。这可以给我们省下来很可观的计算量，因为我们现在只在需要的情况下计算光照。

### 为什么延迟渲染对MSAA支持不好
[抗锯齿](https://learnopengl-cn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/11%20Anti%20Aliasing/#_2)

延迟渲染中，丢失了每个像素覆盖的子样本的信息。

# 阴影

## shadowmap实现原理
Unity使用一个额外的Pass来专门更新光源的阴影映射纹理，这个Pass就是LightMode标签被设置为ShadowCaster的Pass。这个Pass的渲染目标不是帧缓存，而是阴影映射纹理。Unity首先把摄像机放置到光源位置上，然后调用该Pass，通过对顶点变换后得到光源空间下的位置，并据此来输出深度信息到阴影映射纹理中。

## 接收阴影和投射阴影是两个过程
- 如果我们想要一个物体接收来自其他物体的阴影，就必须在Shader中对阴影映射纹理（包括屏幕空间的阴影图）进行采样，把采样结果和最后的光照结果相乘来产生阴影效果。
- 如果我们想要一个物体向其他物体投射阴影，就必须把该物体加入到光源的阴影映射纹理的计算中，从而让其他物体在对阴影映射纹理采样时可以得到该物体的相关信息。在Unity中，这个过程是通过为该物体执行LightMode为ShadowCaster的Pass来实现的。

## 屏幕空间的阴影算法原理

Unity根据光源的阴影映射纹理，以及摄像机的深度纹理，来得到屏幕空间的阴影图。如果摄像机的深度图中记录的表面深度大于转换到阴影映射纹理中的深度值，就说明该表面虽然是可见的，但是却处于该光源的阴影中。通过这样的方式，阴影图就包含了屏幕空间中所有有阴影的区域。如果我们想要一个物体接收来自其它物体的阴影，只需要在Shader中对阴影图进行采样。阴影图是屏幕空间下的，所以我们需要把坐标从模型空间变换到屏幕空间中，再使用这个坐标对阴影图进行采样。

## SHADOW_COORDS TRANSFER_SHADOW SHADOW_ATTENUATION
这些内置宏帮助我们在必要时计算光源的阴影。


# 纹理

## 纹理映射坐标
顶点uv坐标通常被归一化到[0,1]的范围内。不再[0,1]范围内的纹理坐标和纹理的平铺模式有关。

## 纹理滤波
Point模式使用最近邻滤波，在放大或缩小时，它的采样像素数目通常只有一个，因此图像会看起来有种像素风格的效果。

Bilinear滤波模式使用了线性滤波，对于每个目标像素，它会找到4个相邻像素，然后对他们进行线性插值混合后得到最终像素，因此图像看起来被模糊了。

Trilinear滤波几乎和Bilinear一样，只是还会在多级渐远纹理之间进行混合。

## MipMap是什么，作用？
Mipmap技术有点类似于LOD技术，但是不同的是，LOD针对的是模型资源，而Mipmap针对的纹理贴图资源使用Mipmap后，贴图会根据摄像机距离的远近，选择使用不同精度的贴图。

多级渐远纹理技术将纹理提前用滤波处理来得到很多更小的图像，形成了一个图像金字塔，每一层都是对上一层图像降采样的结果。这样在运行时就可以快速得到结果像素。

缺点：会占用内存，因为mipmap会根据摄像机远近不同而生成对应的八个贴图，所以必然占内存！通常会多占用33%的内存空间。这是一个典型的空间换时间的方法。

优点：会优化显存带宽，用来减少渲染，因为可以根据实际情况，会选择适合的贴图来渲染，距离摄像机越远，显示的贴图像素越低，反之，像素越高！MipMap可以用于跑酷类游戏，当角色靠近时，贴图清晰显示，否则模糊显示。

## 凹凸映射
高度映射

法线映射
- 模型空间的法线纹理
- 切线空间的法线纹理√

切线空间下的法线纹理：
- 可以应用到不同的网格上
- 可以进行uv动画
- 可以重用法线纹理
- 可以压缩，因为Z方向总为正向，只存储XY方向。

要在光照模型中统一各个方向矢量所在的坐标空间，由于法线纹理中存储的法线是切线空间下的方向：
一种选择是在切线空间下进行光照计算，此时我们需要把光照方向，视角方向变换到切线空间下。
一种选择是在世界空间下进行光照计算，此时我们需要把采样得到的法线方向变换到世界空间下。

## 立方体纹理
立方体纹理在实时渲染中最常用于天空盒子(skybox)和环境映射。

反射：使用反射效果的物体通常看起来就像镀了层金属，要模拟反射效果，我们只需要通过入射光线的方向和表面法线方向来计算反射方向，再利用反射方向对立方体纹理采样。使用CG的reflect函数。

折射：得到折射方向后就直接对立方体纹理进行采样。使用CG的refract函数。

## 菲涅尔反射
当光线照射到物体表面上时，一部分发生反射，一部分进入物体内部，发生折射或散射。被反射的光和入射光之间存在一定的比率关系，这个比率关系可以通过菲涅尔等式进行计算。

几乎任何物体或多或少都包含了菲涅尔效果，这是基于物理的渲染中非常重要的一项高光反射计算因子。

## 渲染目标纹理
现代GPU允许我们把整个三维场景渲染到一个中间缓冲中，即Render Target Texture，而不是传统的帧缓冲或后备缓冲。

使用渲染纹理的效率往往好于GrabPass，尤其是移动设备上。使用渲染纹理，我们可以自定义渲染纹理的大小。

## 命令缓冲(Command Buffer)
命令缓冲允许我们扩展Unity的渲染流水线。使用命令缓冲我们可以得到类似抓屏的效果，它可以在不透明物体渲染之前把当前的图像复制到一个临时的渲染目标纹理中，然后在那里进行一些额外的操作。

## 深度纹理

深度纹理实际上就是一张渲染纹理，存储的是高精度的深度值。由于被存储在一张纹理中，深度纹理里的深度值范围是[0,1]，而且通常是非线性分布的。这些深度值来源于顶点变换后得到的归一化设备坐标。

统一的深度纹理采样宏：SAMPLE_DEPTH_TEXTURE()

LinearEyeDepth()负责把深度纹理的采样结果转换到视角空间下的深度值。

Linear01Depth会返回一个范围在[0,1]的线性深度值。

解码深度+法线信息：DecodeDepthNormal()

这里介绍得很详细。[LearnOpenGL - Depth testing](https://learnopengl.com/Advanced-OpenGL/Depth-testing)

[Custom shaders with depth sampling](https://www.edraflame.com/blog/custom-shader-depth-texture-sampling/)

## 噪声纹理

>[White Noise](https://www.ronja-tutorials.com/post/024-white-noise/)

For many effects we want random numbers to generate patterns or other things in our shaders. Directly using those random values generates a pattern we call “white noise”. 

>[Value Noise](https://www.ronja-tutorials.com/post/025-value-noise/)

In the last tutorial we learned how to generate random numbers in a shader. In this one we’ll go into interpolating between random numbers to generate noise that’s smoother and gradually changes.

>[Perlin Noise](https://www.ronja-tutorials.com/post/026-perlin-noise/)

One of other common form of noise is perlin noise. Perlin noise is one implementation of so called “gradient noise” similarly to value noise it’s based on cells so it can be easily repeated and looks smooth. What differentiates it from value noise is that instead of interpolating the **values**, the values are based on **inclinations**. 

>[Layered Noise](https://www.ronja-tutorials.com/post/027-layered-noise/)


>[Voronoi Noise](https://www.ronja-tutorials.com/post/028-voronoi-noise/)


>[Tiling Noise](https://www.ronja-tutorials.com/post/029-tiling-noise/)

# 透明效果

## 如何渲染半透明物体
透明通道（Alpha Channel）。
开启透明混合。

## 透明物体和不透明物体渲染顺序
渲染引擎一般都会先对物体进行排序，再渲染。常用的方法是：
- 先渲染所有不透明物体，并开启它们的深度测试和深度写入。
- 把半透明物体按它们距离摄像机的远近进行排序，然后按照从后往前的顺序渲染这些半透明物体，并开启它们的深度测试，但关闭深度写入。

## 透明渲染队列，和普通渲染队列有什么不同，系统如何处理的？

用SubShader的Queue标签来决定我们的模型将归于哪个渲染队列。
unity内部使用一系列整数索引来表示每个渲染队列，且索引号越小表示越早被渲染。

名称|队列索引号|描述
---|---|---
Background|1000|绘制背景，在其它任何队列之前渲染
Geometry|2000|默认渲染队列，不透明物体使用这个队列
AlphaTest|2450|需要透明度测试的物体使用这个队列。
Transparent|3000|按照**从后往前**的顺序进行渲染，任何使用了透明度混合的物体都应该使用这个队列
Overlay|4000|任何需要最后渲染的物体使用此队列
 
## 请问alpha test在何时使用？能达到什么效果？
只要一个片元的透明度不满足条件（通常是小于某一个阈值），那么它对应的片元就会被舍弃。被舍弃的片元将不会再进行任何处理，也不会对颜色缓冲产生任何影响。否则，就会按照普通的不透明物体的处理方式来处理它。

## alpha blend工作原理
这种方法可以得到真正的半透明效果，它会使用当前片元的透明度作为混合因子，与已经存储在颜色缓冲中的颜色值进行混合，得到新的颜色。但是透明度混合需要关闭深度写入，这使得我们要非常小心物体的渲染顺序。

## ShaderLab的混合命令

为了进行混合，我们需要使用混合命令Blend。

混合等式 Blend SrcFactor DstFactor, SrcFactorA DstFactorA

混合操作 BlendOp Add/Sub/Max/Min.......

Unity的Shader中，Blend SrcAlpha OneMinusSrcAlpha这句话是什么意思？
作用就是Alpha混合。公式：最终颜色 = 源颜色 x 源透明值 + 目标颜色 x（1 - 源透明值）

# 屏幕后处理

实现屏幕后处理的基础在于得到渲染后的屏幕图像，即抓取屏幕。Unity为我们提供了一个方便的接口 OnRenderImage 函数。

>ZTest Always Cull Off ZWrite Off

屏幕后处理实际上是在场景中绘制了一个与屏幕同宽同高的四边形面片，为了防止它对其他物体产生影响，我们需要设置相关的渲染状态。在这里我们关闭了深度写入，是为了防止它“挡住”在其后面被渲染的物体。这些状态设置可以认为是用于屏幕后处理Shader的标配。

## Bloom
根据一个阈值提取出图像中的较量区域，把它们存储在一张渲染纹理中，再利用高斯模糊对这张渲染纹理进行模糊处理，模拟光线扩散的效果，最后再将其和原图像进行混合，得到最终的效果。

## 动态模糊
一种方法，使用一块累计缓存，不断地把当前渲染图像叠加到之前的渲染图像中。

另一种常用方法，创建和使用速度缓存，这个缓存中存储了各个像素当前的运动速度，然后利用该值来决定模糊的方向和大小。

根据深度纹理重建每个像素在世界空间下的位置：
首先对图像空间下的视锥体射线进行插值，这条射线存储了该像素在世界空间下到摄像机的方向信息。然后我们把该射线和线性化后的视角空间下的深度值相乘，再加上摄像机的世界位置，就可以得到该像素在世界空间下的位置。

## 边缘检测
使用深度和法线纹理进行边缘检测。

为特定物体添加描边效果：使用Graphics.DrawMesh或Graphics.DrawMeshNow函数把需要描边的物体再渲染一遍（深度和法线纹理只剩下该物体的数据），然后使用边缘检测算法计算深度或法线纹理中每个像素的梯度值，判断它们是否小于某个阈值，如果是，就用clip()函数将该像素剔除掉。

# 非真实感渲染(Non-Photorealistic Rendering)

## 卡通渲染思路

使用漫反射系数对一张一维纹理（渐变纹理RampTex）采样，以控制漫反射色调。

模型的高光往往是一块块分界明显的纯色区域。
```
float spec = dot(worldNormal, worldHalfDir);
spec = lerp(0,1,smoothstep(-w,w, spec - threshold));
```

卡通风格的渲染通常还需要在物体边缘部分绘制轮廓。

## 描边

- 基于观察角度和表面法线的轮廓线渲染：使用视角方向和表面法线的点乘结果来得到轮廓线的信息。简单快速，可以在一个Pass中就得到渲染结果，但局限性很大，很多模型渲染出来的描边效果不尽如人意。

- 过程式几何轮廓线渲染：第一个Pass渲染背面的面片，并使得轮廓可见；第二个Pass再渲染正面的面片。快速有效，适用于大多数表面平滑的模型。不适合立方体这种平整的模型。

- 基于图像处理的轮廓线渲染：屏幕后处理实现的边缘检测。适用于任何种类的模型。但是深度和法线变化很小的轮廓无法被检测出来。

- 基于轮廓边检测的轮廓线渲染：检测一条边是否是轮廓边，要检查两个相邻的三角形面片的朝向是否相反。缺点是实现比较复杂。

- 混合上述几种的渲染方法：首先找出精确的轮廓边，把模型和轮廓边渲染到纹理中，再使用图像处理的方式识别出轮廓线，并在图像空间下进行风格化渲染。

## Outlines

>[Hull Outlines](https://www.ronja-tutorials.com/post/020-hull-outline/)

First we draw our object as usual and then we draw it again, but we change the vertices a bit so it’s only visible around the original object, drawing a outline.

>[Outlines via Postprocessing](https://www.ronja-tutorials.com/post/019-postprocessing-outlines/)

Doing outlines via postprocessing has many advantages. It’s better at detecting edges than the alternative (inverted hull outlines) and you don’t have to change all of your materials to give them the outline effect.

>[Sprite Outlines](https://www.ronja-tutorials.com/post/049-sprite-outlines/)

The idea is that we sample the texture at multiple spots around the uv point and remember the biggest value of the alpha channel we find. When a Pixel is not visible for the original texture sample, but we can find a higher alpha value when looking at the neighboring pixels, then we color in the outline.

>[Object Outlines](https://www.ronja-tutorials.com/post/052-object-outline/)

It uses the same base idea of sampling neighboring pixels as the sprite based one, but can be applied to 3d models. It uses a postprocessing effect, yet can be applied to distinct objects you choose. Because of those properties this technique is mostly useful to show selected objects in 3d contexts.

>[Edge Detection Outlines](https://alexanderameye.github.io/notes/edge-detection-outlines/)

# 渲染优化技术

## [Graphics performance fundamentals](https://docs.unity3d.com/cn/2022.1/Manual/OptimizingGraphicsPerformance.html)

>Reducing the CPU cost of rendering

Usually, the greatest contributor to CPU rendering time is the cost of sending rendering commands to the GPU.

- 减少绘制的object数量
  - 考虑减少场景中的object
  - 使用遮挡剔除，摄像机裁剪远平面，不同的裁剪层

- 减少绘制每个object的次数
  - 使用光照贴图
  - 如果使用Forward rendering，减少每像素实时光照
  - 实时阴影很昂贵
  - 如果使用了反射探针，确保优化使用

>Reducing the GPU cost of rendering

有三种导致GPU不能及时渲染一帧的主要原因。

如果应用程序的顶点处理能力受限，通常意味着顶点数量太多：
- 减少顶点着色器的花费
- 优化网格
- 使用Level Of Detail

如果应用程序被填充率限制，GPU绘制了超过它能力的像素（片元）数量：
- 识别并减少重绘。透明元素经常导致重绘，例如UI，粒子和精灵。
- 减少片元着色器的花费，减少实时光照，减少实时阴影。
- 如果使用了内置着色器，使用相应的Mobile或Unlit版本。
- 使用动态分辨率。
- 使用Shader的LOD技术

如果应用程序被显存带宽限制，GPU尝试读取读写超过它处理能力的数据量，通常意味着纹理太多太大：
- 使用Mipmap
- 使用合适的纹理压缩技术

>Reducing the frequency of rendering

有时候，降低帧率会使程序受益。这不会减少CPU和GPU在渲染一帧上的花费，但是像unity做得那样降低频率，避免影响其它操作的执行频率（像是脚本）。

降低程序的帧率，避免不必要的电池消耗，避免设备过热。

在菜单和暂停等页面中大多是静态内容的场景中，可以降低帧率。

为了预防输入延迟，可以在输入期间暂时提高帧率，提高响应速度。

## 优化shader

float,half,还是fixed。尽可能使用精度较低的类型。

在使用插值寄存器把数据从顶点着色器传递给下一个阶段时，使用尽可能少的插值变量。

避免不必要的计算。如果毫无节制地在Shader中进行了大量计算，那么需要的指令寄存器数目会超过当前可支持的数目。

尽可能避免使用类似sin，tan，log等较为复杂的数学运算，改用查找表作为替代。

尽可能不使用discard操作，因为这会影响硬件的某些优化。

### shader中的if会造成性能影响以及优化

GPU使用了不同于CPU的技术来实现分支语句，在Shader中使用流程控制语句，会降低GPU的并行处理操作。

一个解决办法是，我们应该尽量把计算向流水线上端移动。例如把放在片元着色器中的计算放到顶点着色器中，或者直接在CPU中进行预计算，再把结果传递给Shader。

如果不可避免要使用分支语句，一些建议是
- 条件变量最好是常数，在Shader运行过程中不会发生变化
- 每个分支中包含的操作指令数尽可能少
- 分支的嵌套层数尽可能少

## Drawcall

DrawCall很简单，就是cpu对图形绘制接口的调用，CPU通过调用图形库（directx/opengl）接口，命令GPU进行渲染操作。Unity中，每次引擎准备数据并通知GPU的过程称为一次Draw Call。Draw Call是一个命令，由CPU发起，由GPU执行，该命令仅仅指向一个需要被渲染的**图元列表**。

DrawCall越高对显卡的负担就越大，同时DrawCall过高对GPU和CPU占有都会提高，GPU需要频繁的进行渲染工作，CPU需要不断的计算去给GPU提供绘制的图元数据，有可能会造成游戏卡顿等问题。

### SetPass Call 是什么？

为了实现相应的效果，Shader里或许会包含很多的Pass,每当GPU即将去运行一个Pass之前，就会产生一个“SetPass call”，因此在描述渲染性能开销上，“SetPass calls”更加有说服力。

### 如何降低DrowCall？

1. 动态批处理，如果动态物体共用相同的材质，那么Unity会自动对这些物体进行批处理，你可以在buildSetting中对其进行设置

2. 静态批处理，只要物体不移动，并且拥有相同的材质，那么就可以进行静态批处理。因此静态批处理比动态批处理更加有效，我们可以把静止的物体（在游戏中永远不会移动、旋转和缩放）标记为静态的，使用静态批处理操作需要2倍的内存开销来存储合并后的几何数据。

3. 调整渲染顺序，说白了，就是同渲染数据相同的物体先渲染完，比如说A，C的材质相同，B的材质与A，C不同，如果先渲染A再渲染B再渲染C就是3个DC，但如果先渲染A，再渲染C，最后渲染B就是两个DC。

4. 再有就是同一界面尽量使用同一图集。

其实说了这么些个方法，总结来说很简单，既然要优化DC，我们就是要从产生DC的原理上入手，我们所有的一切操作做的都是一件事儿，就是能一次渲染完成的事儿就没必要多渲染几遍。

## 批处理

[[Unity优化] Unity中的批处理优化与GPU Instancing](https://www.jianshu.com/p/ac9d2d67f865?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)

批处理需要把多个模型变换到世界空间下再合并它们，因此，如果Shader中存在一些基于模型空间下的坐标的运算，那么往往会得到错误的结果。

### Dynamic Batching

如果动态物体共用着相同的材质，那么Unity会自动对这些物体进行批处理。动态批处理操作是自动完成的，并不需要你进行额外的操作。而且物体是可以移动的，因为每帧unity会重新合并一次网格。

但是限制很多。顶点数量、镜像信息、材质、渲染器、不能使用Multi-pass着色器的情况...

Dynamic Batching通过将所有物体的顶点转换为CPU上的世界空间来工作，所以它只能在渲染Draw Call的工作量小于CPU顶点转换工作量的时候，才会起到提高性能的作用。

### Static Batching
自由度很高，限制很少，缺点可能会占用更多的内存，而且经过静态批处理后的所有物体都不可以再移动了。

### GPU Instancing
提高图形性能的另一个好办法是使用GPU Instancing。GPU Instancing的最大优势是可以减少内存使用和CPU开销。当使用GPU Instancing时，不需要打开批处理，GPU Instancing的目的是一个网格可以与一系列附加参数一起被推送到GPU。要利用GPU Instancing，您必须使用相同的材质，且可以传递额外的参数到着色器，如颜色，浮点数等。虽然实例化的物体共享相同的网格和材质，但您可以使用MaterialPropertyBlock API为每一个物体设置单独的着色器属性。

如果一个游戏对象被标记为“Static”并且打开了Static Batching，那么这个游戏对象就不能进行GPU Instancing，检视器中会出现一个警告框，提示“静态批处理”标志可以在播放器设置（Player Settings）中取消。如果游戏对象支持Dynamic Batching，但是它使用的某个材质可以进行实例化，那么这个游戏对象将不会被批处理，并且将被自动实例化。
当使用Forward Rendering渲染模式，受多个灯光影响的物体无法有效地实例化。只有Base Pass可以有效地利用实例化，而不是添加的Pass。此外，使用光照贴图或受不同光或Reflection probe影响的物体无法实例化。

## 其它

### LOD是什么，优缺点是什么？
[网格的细节级别 (LOD)](https://docs.unity3d.com/cn/2022.1/Manual/LevelOfDetail.html)

LOD(Level of detail)多层次细节，是最常用的游戏优化技术。它按照模型的位置和重要程度决定物体渲染的资源分配，降低非重要物体的面数和细节度，从而获得高效率的渲染运算。

缺点是增加了内存。

要使用 LOD，必须有一个包含 LOD Group 组件的游戏对象。LOD Group 组件提供了相应控件来定义 LOD 在此游戏对象上的行为方式，并会引用 Unity 为每个 LOD 级别显示或隐藏的游戏对象。

### Cast Shadows
默认情况下，MeshRenderder组件的Cast Shadows是开启的。​阴影的渲染可以让游戏的光线增加真实度和深度感，但是某些情况下可能并不需要。在复杂场景中，可能会造成多余的阴影计算，阴影效果最后也看不见。

因此若场景有的对象是否有阴影对整体效果没有影响的话，就关闭这个选项。不计算阴影可以省下CPU时间。

## Light Culling Mask
​在复杂场景中，许多光线紧靠彼此，你可能觉得光线不能影响特定对象。根据渲染流程的设置，场景中越多的光照，性能可能就会越差。因此我们要确保光照只影响特定的对象层（例如专门给角色打光的光源，设置成只影响角色），尤其是多光源和多对象彼此紧靠的时候。

### MeshRender中material和sharedmaterial的区别？
修改sharedMaterial将改变所有物体使用这个材质的外观，并且也改变储存在工程里的材质设置。
不推荐修改由sharedMaterial返回的材质。如果你想修改渲染器的材质，使用material替代。
（在Editor自定开发中，只能用sharedMaterial，sharedMaterial自动等于material）

### Cloned Materials
谨防克隆的材质，因为访问任何渲染器的材质属性都会导致克隆材质，即使未分配任何内容。克隆的材质将不会被垃圾收集，只有在更改场景或调用Resources.UnloadUnusedAssets（）时才会清除。如果要访问只读材质，可以使用customRenderer.sharedMaterial。


# 基于物理的渲染

## PBS
BRDF

高光反射项：描述表面反射的部分，微面元理论

漫反射项：描述此表面散射

金属工作流（Metallic workflow）：高光反射颜色由漫反射颜色和金属值衍生而来。

高光反射工作流（Specular workflow）：可以直接指定表面的高光反射颜色。

## PBS适合什么样的游戏

优点：我们只需要一个万能的Shader就可以渲染相当一大部分类型的材质；PBS保证在各种光照条件下，材质都可以自然地和光源进行交互，而不需要我们频繁地调整材质参数。

缺点：需要更复杂的光照配合，例如大量使用光照探针和反射探针。使用PBS也需要开启HDR以及一些必不可少的屏幕特效。使用PBS对美术人员来说同样是个挑战。

## 伽马校正 gamma correction
要想渲染出更符合真实光照环境的场景需要使用线性空间。Unity默认的空间时伽马空间，在伽马空间下进行渲染会导致很多非线性空间下的计算，从而引入一些误差。从伽马空间转换到线性空间，需要进行伽马校正。

在正常光照条件下，人眼对较暗区域的变化更加敏感。对亮部区域使用这么多颜色是一种浪费，应该把更多的空间用来存储更多的暗部区域，这样存储空间就可以充分利用起来。

使用0.45的编码伽马来对输入的**亮度**进行编码，编码后的图像，图像中0.5**像素值**对应的亮度大约为0.22，因为0.5 = 0.22^0.45。

显示伽马：对图像进行解码，还原捕捉到的亮度（0.5变成0.22）。如果我们直接输出渲染结果（线性空间）而不进行任何处理，在经过显示器的显示伽马处理后，会导致图像整体偏暗，出现失真。

                摄像机                                   显示器
    捕获亮度(线性) ---> 像素值(非线性) -----> 像素值(非线性) ---> 显示的亮度(线性)
                编码伽马                                显示伽马
                                                     
    像素值往往大于亮度值。

颜色空间设置：

当选择伽马空间时，实际上就是放任模式，不会对shader的输入进行任何处理，即使输入可能是非线性的；也不会对输出像素进行任何处理，这意味着输出的像素会经过显示器的显示伽马转换后得到非预期的亮度，通常表现为整个场景比较昏暗。

当选择线性空间时，Unity会把输入纹理设置为sRGB模式，硬件对纹理进行采样时会自动将其转换到线性空间中；并且GPU会在Shader写入深度缓冲前自动进行伽马矫正。

## HDR与LDR的区别

动态范围指的是最高的最低的亮度值之间的比值。

HDR使用远远高于8位的精度(如32位)来记录亮度信息，从而我们可以更加精确地反映真实的光照环境。使用HDR可以让我们不会失去高亮度区域的颜色值，提供了更真实的光照效果，并为一些屏幕后处理提供了更多的控制能力。

HDR需要更大的显存空间，渲染速度变慢，一些硬件不支持HDR，无法使用硬件抗锯齿。

# 解析几何

## 相交测试

静态：检查两个处于静止状态的图元并检测两个图元是否相交。

动态：将检查两个移动图元，并检测两个图元是否相交以及何时相交。运动是以参数来表示的，因此这种测试还有指示图元何时相交的时间值(参数t的值)。要执行此测试，可以通过组合两个位移矢量来获得单个相对位移矢量，从而描述这两个图元相对于彼此的移动方式。因此动态测试通常涉及一个固定图元和一个移动图元。

## 点到平面的距离如何计算

设平面法线n是单位矢量，d是从原点到平面的有符号距离。

平面的矢量表示法：p·n = d

设点q不在平面上，p是平面与q最近的点，显然从p到q的矢量垂直于平面。

    p + a·n = q
    (p + a·n)n = q·n
    p·n + a·n·n = q·n
    d + a = q·n
    a = q·n - d

## 光线和平面的交点

    假设光线进行参数化定义：p(t) = p0 + tm
    平面以标准隐式方法定义：p·n = d
    则有：(p0 + tm)·n = d

## 如何判断是凸多边形还是凹多边形
对于具有n个顶点的凸多边形来说，内角之和为(n-2)*180，而凹多边形的内角之和小于(n-2)*180

另一种办法是，搜索作为凹陷点的顶点，每个顶点应该朝同一个方向转动，任何沿相反方向转动的顶点都是凹陷点。

## AABB包围盒 OBB包围盒

    AABB：轴向对齐包围盒(Axially Aligned Bounding Box)
    OBB： 定向包围盒(Oriented Bounding Box)

轴向对齐的包围盒更容易创建和使用，更重要的是，可以将OBB视为具有定向的AABB；每个包围盒都是某些坐标空间中的AABB；实际上，任何一个轴垂直于盒子的边的包围盒都是AABB。换句话说，**AABB和OBB之间的差异不在于盒子本身中，而在于是否在与包围盒对齐的坐标空间中执行计算。**

AABB的表示：建议使用Pmin Pmax来表示包围盒。

如何判断相交与分离？

执行分离轴测试。分别检查各个轴。
```
if(a.min.x >= b.max.x) return false;
if(a.max.x <= b.min.x) return false;

if(a.min.y >= b.max.y) return false;
if(a.max.y <= b.min.y) return false;

if(a.min.z >= b.max.z) return false;
if(a.max.z <= b.min.z) return false;

return true;
```

# 资料
## 《Unity Shader入门精要》

[源代码](https://github.com/candycat1992/Unity_Shaders_Book)

## [Shader Tutorials by Ronja](https://www.ronja-tutorials.com/)
很“基础”的shaderlab教程，

这里是教程源代码[ronja-tutorials/ShaderTutorials](https://github.com/ronja-tutorials/ShaderTutorials)
